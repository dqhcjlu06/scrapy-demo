
<!-- TOC -->

- [1. 爬虫需要的基本知识：](#1-爬虫需要的基本知识)
    - [1.1. 网页基本知识：](#11-网页基本知识)
    - [1.2. 一些分析语言，为接下来解析网页内容做准备](#12-一些分析语言为接下来解析网页内容做准备)
        - [1.2.1. 正则表达式：](#121-正则表达式)
        - [1.2.2. XPATH：高效的分析语言，](#122-xpath高效的分析语言)
        - [1.2.3. Beautifulsoup:](#123-beautifulsoup)
- [2. 辅助工具](#2-辅助工具)
    - [2.1. F12 开发者工具：](#21-f12-开发者工具)
    - [2.2. 抓包工具：](#22-抓包工具)
    - [2.3. XPATH CHECKER (火狐插件）：](#23-xpath-checker-火狐插件)
    - [2.4. 正则表达测试工具：](#24-正则表达测试工具)
- [各种经验总结](#各种经验总结)
    - [现在开始进入抓取时间，上各种模块吧！](#现在开始进入抓取时间上各种模块吧)
    - [华丽丽的scrapy](#华丽丽的scrapy)
    - [遇到动态页面怎么办？](#遇到动态页面怎么办)
    - [遇到反爬虫策略验证码之类咋整？（不想折腾的直接第四个）](#遇到反爬虫策略验证码之类咋整不想折腾的直接第四个)

<!-- /TOC -->
# 1. 爬虫需要的基本知识：
## 1.1. 网页基本知识：
> 基本的HTML语言知识（知道href等大学计算机一级内容即可）
理解网站的发包和收包的概念（POST GET）
稍微一点点的js知识，用于理解动态网页（当然如果本身就懂当然更好啦）

## 1.2. 一些分析语言，为接下来解析网页内容做准备
### 1.2.1. 正则表达式：
- 扛把子技术，总得会最基础的：
### 1.2.2. XPATH：高效的分析语言，
- 表达清晰简单，掌握了以后基本可以不用正则 参考： [XPath教程](https://www.w3school.com.cn/xpath/index.asp)
### 1.2.3. Beautifulsoup:
- 丽汤模块解析网页神器,一款神器，如果不用一些爬虫框架（如后文讲到的scrapy），配合request，urllib等模块（后面会详细讲），可以编写各种小巧精干的爬虫脚本
官网文档：[Beautiful Soup文档](https://beautifulsoup.readthedocs.io/zh_CN/latest/) 参考案例：

# 2. 辅助工具
## 2.1. F12 开发者工具：
- 看源代码：快速定位元素
- 分析xpath：1、此处建议谷歌系浏览器,可以在源码界面直接右键看
## 2.2. 抓包工具：
- 推荐httpfox，火狐浏览器下的插件,比谷歌火狐系自带的F12工具都要好，可以方便查看网站收包发包的信息
## 2.3. XPATH CHECKER (火狐插件）：
非常不错的xpath测试工具，但是有几个坑，都是个人踩过的，，在此告诫大家：     1、xpath checker生成的是绝对路径，遇到一些动态生成的图标（常见的有列表翻页按钮等），飘忽不定的绝对路径很有可能造成错误，所以这里建议在真正分析的时候，只是作为参考     2、记得把如下图xpath框里的“x:”去掉，貌似这个是早期版本xpath的语法，目前已经和一些模块不兼容（比如scrapy），还是删去避免报错

## 2.4. 正则表达测试工具：
[在线正则表达式测试](https://tool.oschina.net/regex/)，拿来多练练手，也辅助分析！里面有很多现成的正则表达式可以用，也可以进行参考！

# 各种经验总结
## 现在开始进入抓取时间，上各种模块吧！
> python的火，很大原因就是各种好用的模块，这些模块是居家旅行爬网站常备的——

> urllib
> urllib2
> requests

## 华丽丽的scrapy

## 遇到动态页面怎么办？
> selenium（会了这个配合scrapy无往不利，是居家旅行爬网站又一神器，下一版更新的时候会着重安利，因为这块貌似目前网上的教程还很少）
phantomJS（不显示网页的selenium）

## 遇到反爬虫策略验证码之类咋整？（不想折腾的直接第四个）
> PIL
opencv
pybrain
打码平台